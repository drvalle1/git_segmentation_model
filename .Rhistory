tmp=b0[i]+b1*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='red')
plot(NA,NA,xlim=c(-1,1),ylim=c(0,0.5))
cond=res1$converge==1 & res1$b0.true==b0[i] & res1$nobs==nobs[j]
res2=res1[cond,]
#get estimated curves
for (k in 1:nrow(res2)){
b0.estim=res2$b0[k]
b1.estim=res2$b1[k]
tmp=b0.estim+b1.estim*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='grey')
}
#true curve
tmp=b0[i]+b1*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='red')
cond=res1$converge==1 & res1$b0.true==b0[i] & res1$nobs==nobs[j]
res2=res1[cond,]
#get estimated curves
res.estim=matrix(NA,length(seq1),nrow(res2))
for (k in 1:nrow(res2)){
b0.estim=res2$b0[k]
b1.estim=res2$b1[k]
tmp=b0.estim+b1.estim*seq1
prob=exp(tmp)/(1+exp(tmp))
res.estim[,k]=prob
}
plot(NA,NA,xlim=c(-1,1),ylim=c(0,max(res.estim)))
for (k in 1:nrow(res2)){
lines(seq1,res.estim[,k],col='grey')
}
#true curve
tmp=b0[i]+b1*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='red')
seq1=seq(from=-1,to=1,length.out=1000)
for (i in 1:length(b0)){
for (j in 1:length(nobs)){
cond=res1$converge==1 & res1$b0.true==b0[i] & res1$nobs==nobs[j]
res2=res1[cond,]
#get estimated curves
res.estim=matrix(NA,length(seq1),nrow(res2))
for (k in 1:nrow(res2)){
b0.estim=res2$b0[k]
b1.estim=res2$b1[k]
tmp=b0.estim+b1.estim*seq1
prob=exp(tmp)/(1+exp(tmp))
res.estim[,k]=prob
}
plot(NA,NA,xlim=c(-1,1),ylim=c(0,max(res.estim)),main=c(b0[i],nobs[j]))
for (k in 1:nrow(res2)){
lines(seq1,res.estim[,k],col='grey')
}
#true curve
tmp=b0[i]+b1*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='red')
}
}
rm(list=ls(all=TRUE))
set.seed(1)
#Is the estimated variance of beta smaller for case-control than for random sampling?
nsim=100
nobs=10000
b0=-c(6:1)
b1=-2
oo=1
conv.cc=conv.rs=warn.rs=rep(NA,nsim*length(b0))
res.cc=res.rs=matrix(NA,nsim*length(b0),8)
for (i in 1:nsim){
# print(i)
for (k in 1:length(b0)){
b0a=b0[k]
x=runif(nobs,min=-1,max=1)
tmp=b0a+b1*x
prob=exp(tmp)/(1+exp(tmp)); mean(prob)
y=rbinom(nobs,size=1,prob=prob)
#case-control
ind1=which(y==1)
ind0=sample(which(y==0),size=length(ind1))
ind=c(ind0,ind1)
dat=data.frame(y=y[ind],x=x[ind])
mod=glm(y~x,data=dat,family='binomial')
cov.true=vcov(mod)
conv.cc[oo]=mod$converged
#compare to my equations
xmat=data.matrix(cbind(1,dat$x))
pred=predict(mod,type='response')
w=diag(pred*(1-pred))
cov.est=solve(t(xmat)%*%w%*%xmat)
res.cc[oo,]=c(as.numeric(cov.true),as.numeric(cov.est))
prec=t(xmat)%*%w%*%xmat
print(diag(1/prec),diag(cov.est))
#random sampling
ind=sample(1:nobs,size=length(ind))
dat=data.frame(y=y[ind],x=x[ind])
mod=glm(y~x,data=dat,family='binomial')
cov.true=vcov(mod)
conv.rs[oo]=mod$converged
#compare to my equations
xmat=data.matrix(cbind(1,dat$x))
pred=predict(mod,type='response')
w=diag(pred*(1-pred))
cov.est=solve(t(xmat)%*%w%*%xmat)
res.rs[oo,]=c(as.numeric(cov.true),as.numeric(cov.est))
oo=oo+1
}
}
prec
diag(1/prec)
diag(1/prec)
diag(cov.est)
rm(list=ls(all=TRUE))
set.seed(1)
#Is the estimated variance of beta smaller for case-control than for random sampling?
nsim=100
nobs=10000
b0=-c(6:1)
b1=-2
oo=1
conv.cc=conv.rs=warn.rs=rep(NA,nsim*length(b0))
res.cc=res.rs=matrix(NA,nsim*length(b0),8)
for (i in 1:nsim){
# print(i)
for (k in 1:length(b0)){
b0a=b0[k]
x=runif(nobs,min=-1,max=1)
tmp=b0a+b1*x
prob=exp(tmp)/(1+exp(tmp)); mean(prob)
y=rbinom(nobs,size=1,prob=prob)
#case-control
ind1=which(y==1)
ind0=sample(which(y==0),size=length(ind1))
ind=c(ind0,ind1)
dat=data.frame(y=y[ind],x=x[ind])
mod=glm(y~x,data=dat,family='binomial')
cov.true=vcov(mod)
conv.cc[oo]=mod$converged
#compare to my equations
xmat=data.matrix(cbind(1,dat$x))
pred=predict(mod,type='response')
w=diag(pred*(1-pred))
prec=t(xmat)%*%w%*%xmat
cov.est=solve(prec)
res.cc[oo,]=c(as.numeric(cov.true),as.numeric(cov.est))
print(c(diag(1/prec),diag(cov.est)))
#random sampling
ind=sample(1:nobs,size=length(ind))
dat=data.frame(y=y[ind],x=x[ind])
mod=glm(y~x,data=dat,family='binomial')
cov.true=vcov(mod)
conv.rs[oo]=mod$converged
#compare to my equations
xmat=data.matrix(cbind(1,dat$x))
pred=predict(mod,type='response')
w=diag(pred*(1-pred))
cov.est=solve(t(xmat)%*%w%*%xmat)
res.rs[oo,]=c(as.numeric(cov.true),as.numeric(cov.est))
oo=oo+1
}
}
seq1=seq(from=0.01,to=100,length.out=10000)
fim=data.frame(param=seq1,p95=pgamma(2,seq1,seq1))
seq1=seq(from=0.01,to=100,length.out=10000)
fim=data.frame(param=seq1,p95=pgamma(2,seq1,seq1))
diff1=abs(fim$p95-2)
which(diff1==min(diff1))
diff1
tail(diff1)
seq1=seq(from=0.01,to=100,length.out=10000)
fim=data.frame(param=seq1,p95=pgamma(2,seq1,seq1))
diff1=abs(fim$p95-0.95)
which(diff1==min(diff1))
seq1=seq(from=0.01,to=100,length.out=10000)
fim=data.frame(param=seq1,p95=pgamma(2,seq1,seq1))
diff1=abs(fim$p95-0.95)
which(diff1==min(diff1))
fim[356,]
param=fim$param[356]
seq1=seq(from=0.01,to=10,length.out=10000)
plot(seq1,dgamma(seq1,param,param),type='l')
param
z=rgamma(100000,param,param)
mean(z<2)
mean(z)
mean(z<0.1)
rm(list=ls(all=TRUE))
setwd('U:\\uf\\courses\\stats\\2019 new exercises')
dat=read.csv('water gauge data.csv',as.is=T)
head(dat)
devtools::install_github('yihui/tinytex')
devtools::install_github("rmarkdown")
install.packages('rmarkdown')
install.packages("rmarkdown")
library('mgcv')
?predict.gam
2+2
x=c(5,2)
x[1]
x[2]
x=data.frame(tree.id=1:10,
vol=runif(10))
head(x)
x
x=data.frame(tree.id=1:10,
vol=runif(10))
x$carbon=0.32*x$vol
x
x
tail(x)
plot(carbon~vol,data=x)
x1=x[1:5,]
x1
plot(carbon~vol,data=x
setwd('U:\\teste')
setwd('U:\teste')
setwd('U:\\teste\\stats')
dat=read.csv('esteban.csv',as.is=T)
setwd('U:\\teste')
dat=read.csv('esteban.csv',as.is=T)
head(dat)
dat=read.csv('esteban',as.is=T)
dat=read.csv('estebanl.csv',as.is=T)
x=data.frame(tree.id=1:10,
vol=runif(10))
x
x$carbon=0.32*x$vol
x
x$vol<0.5
setwd('U:\\teste')
dat=read.csv('esteban.csv')
?read.csv
head(dat[,1:3])
?write.csv
?mean
setwd('U:\\teste')
dat=read.csv('esteban.csv',as.is=T)
setwd('U:\\teste')
dat=read.csv('esteban.csv')
str(dat)
dat$software
unique(dat$software)
setwd('U:\\teste')
dat=read.csv('esteban.csv',as.is=T)
str(dat)
x=data.frame(tree.id=1:10,
vol=runif(10))
hist(x$vol)
setwd('U:\\teste')
setwd('U:\\teste')
png('volume histogram.png',width=700,heigth=700)
hist(x$vol)
dev.off()
png('volume histogram.png',width=700,height=700)
hist(x$vol)
dev.off()
rivers
summary(rivers)
summary('rivers')
summary(cars)
summary('cars')
data()
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\poli\\segmentation')
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
mu=runif(nseg,min=5,max=50)
seg.index=rep(1:nseg,times=partition)
obs=data.frame(obs=rnorm(nobs,mean=mu[seg.index],sd=1),
time1=1:nobs)
plot(obs)
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\poli\\segmentation')
dat=read.csv('fake data.csv',as.is=T)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\poli\\segmentation')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
breakpt
mean(dat$time1)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\poli\\segmentation')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#starting values
breakpt=mean(dat$time1)
breakpt.old=breakpt
p=length(breakpt)
rand1=runif(1)
p
p0=1
breakpt.new=sort(c(breakpt.old,runif(1,0,max.time)))
p0=1/3 #death prob 2 -> 1 is (1/3) and birth prob 1
max.time=max(dat$time1)
breakpt.new=sort(c(breakpt.old,runif(1,0,max.time)))
p0=1/3 #death prob 2 -> 1 is (1/3) and birth prob 1 -> 2 is 1.
breakpt.new
runif(1,0,max.time)
runif(1,0,max.time)
runif(1,0,max.time)
runif(1,min=0,max=max.time)
max.time
breakpt.new
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat)
stats.new=get.summary.stats(breakpt=breakpt.new,dat=dat)
setwd('U:\\poli\\segmentation')
source('gibbs functions.R')
rm(list=ls(all=TRUE))
set.seed(1)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
mu=runif(nseg,min=5,max=50)
seg.index=rep(1:nseg,times=partition)
obs=data.frame(obs=rnorm(nobs,mean=mu[seg.index],sd=1),
time1=1:nobs)
plot(obs)
setwd('U:\\GIT_models\\git_segmentation_model')
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#useful stuff
max.time=max(dat$time1)
#starting values
breakpt=mean(dat$time1)
ngibbs=1000
breakpt.old=breakpt
p=length(breakpt)
rand1=runif(1)
p0=1
new.brk=runif(1,min=0,max=max.time)
if (p == 1) {
#birth
if (rand1 < 1/2){
breakpt.new=sort(c(breakpt.old,new.brk))
p0=2/3 #death prob 2 -> 1 is (1/3) and birth prob 1 -> 2 is 1/2.
}
#swap
if (rand1 > 1/2) breakpt.new=new.brk
}
if (p > 1) {
#birth
if (rand1 < 1/3) {
breakpt.new=sort(c(breakpt.old,new.brk))
}
#death
if (rand1 > 1/3 & rand1 < 2/3) {
ind=sample(1:length(breakpt.old),size=1)
breakpt.new=breakpt.old[-ind]
if (p==2) p0=3/2 #birth prob from 1 -> 2 is 1/2 and death prob from 2 -> 1 is 1/3
}
#swap
if (rand1 > 2/3) {
ind=sample(1:length(breakpt.old),size=1)
breakpt.new=sort(c(breakpt.old[-ind],new.brk))
}
}
breakpt.old
breakpt.new
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat)
stats.new=get.summary.stats(breakpt=breakpt.new,dat=dat)
stats.old
stats.new
pold=log.marg.likel(tau2=tau2,mu0=mu0,summary.stats=stats.old)
pold
summary.stats=stats.old
inv.sig2=summary.stats[,'n']+(1/tau2)
sig2=1/inv.sig2
#get mu1
num1=summary.stats[,'sum.x']+(1/tau2)*mu0
den1=summary.stats[,'n']+(1/tau2)
mu1=num1/den1
#get pieces of equation
p1=summary.stats[,'n']*log(2*pi)
p2=log(sig2/tau2)
p3=(mu1^2)/sig2
p4=summary.stats[,'sum.x2']+((mu0^2)/tau2)
p1
p2
p3
p4
log.marg.likel=function(tau2,mu0,summary.stats){
#get sig2
inv.sig2=summary.stats[,'n']+(1/tau2)
sig2=1/inv.sig2
#get mu1
num1=summary.stats[,'sum.x']+(1/tau2)*mu0
den1=summary.stats[,'n']+(1/tau2)
mu1=num1/den1
#get pieces of equation
p1=summary.stats[,'n']*log(2*pi)
p2=log(sig2/tau2)
p3=(mu1^2)/sig2
p4=summary.stats[,'sum.x2']+((mu0^2)/tau2)
sum((1/2)*(-p1+p2+p3-p4))
}
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat)
stats.new=get.summary.stats(breakpt=breakpt.new,dat=dat)
pold=log.marg.likel(tau2=tau2,mu0=mu0,summary.stats=stats.old)
pnew=log.marg.likel(tau2=tau2,mu0=mu0,summary.stats=stats.new)+log(p0)
pold
pnew
prob=exp(pnew-pold)
prob
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#useful stuff
max.time=max(dat$time1)
#starting values
breakpt=mean(dat$time1)
ngibbs=1000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,tau2=tau2,mu0=mu0)
}
breakpt
abline(v=breakpt)
length(breakpt)
rm(list=ls(all=TRUE))
set.seed(1)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
mu=runif(nseg,min=5,max=50)
seg.index=rep(1:nseg,times=partition)
obs=data.frame(obs=rnorm(nobs,mean=mu[seg.index],sd=1),
time1=1:nobs)
plot(obs~time1,data=obs)
setwd('U:\\GIT_models\\git_segmentation_model')
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#useful stuff
max.time=max(dat$time1)
#starting values
breakpt=mean(dat$time1)
ngibbs=1000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,tau2=tau2,mu0=mu0)
}
abline(h=breakpt,col='grey')
abline(v=breakpt,col='grey')
rm(list=ls(all=TRUE))
set.seed(1)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
mu=runif(nseg,min=5,max=50)
seg.index=rep(1:nseg,times=partition)
obs=data.frame(obs=rnorm(nobs,mean=mu[seg.index],sd=1),
time1=1:nobs)
plot(obs~time1,data=obs)
setwd('U:\\GIT_models\\git_segmentation_model')
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#useful stuff
max.time=max(dat$time1)
#starting values
breakpt=mean(dat$time1)
ngibbs=10000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,tau2=tau2,mu0=mu0)
}
length(breakpt)
abline(v=breakpt,col='grey')
