z=rgamma(100000,param,param)
mean(z<2)
mean(z)
mean(z<0.1)
rm(list=ls(all=TRUE))
setwd('U:\\uf\\courses\\stats\\2019 new exercises')
dat=read.csv('water gauge data.csv',as.is=T)
head(dat)
devtools::install_github('yihui/tinytex')
devtools::install_github("rmarkdown")
install.packages('rmarkdown')
install.packages("rmarkdown")
library('mgcv')
?predict.gam
2+2
x=c(5,2)
x[1]
x[2]
x=data.frame(tree.id=1:10,
vol=runif(10))
head(x)
x
x=data.frame(tree.id=1:10,
vol=runif(10))
x$carbon=0.32*x$vol
x
x
tail(x)
plot(carbon~vol,data=x)
x1=x[1:5,]
x1
plot(carbon~vol,data=x
setwd('U:\\teste')
setwd('U:\teste')
setwd('U:\\teste\\stats')
dat=read.csv('esteban.csv',as.is=T)
setwd('U:\\teste')
dat=read.csv('esteban.csv',as.is=T)
head(dat)
dat=read.csv('esteban',as.is=T)
dat=read.csv('estebanl.csv',as.is=T)
x=data.frame(tree.id=1:10,
vol=runif(10))
x
x$carbon=0.32*x$vol
x
x$vol<0.5
setwd('U:\\teste')
dat=read.csv('esteban.csv')
?read.csv
head(dat[,1:3])
?write.csv
?mean
setwd('U:\\teste')
dat=read.csv('esteban.csv',as.is=T)
setwd('U:\\teste')
dat=read.csv('esteban.csv')
str(dat)
dat$software
unique(dat$software)
setwd('U:\\teste')
dat=read.csv('esteban.csv',as.is=T)
str(dat)
x=data.frame(tree.id=1:10,
vol=runif(10))
hist(x$vol)
setwd('U:\\teste')
setwd('U:\\teste')
png('volume histogram.png',width=700,heigth=700)
hist(x$vol)
dev.off()
png('volume histogram.png',width=700,height=700)
hist(x$vol)
dev.off()
rivers
summary(rivers)
summary('rivers')
summary(cars)
summary('cars')
data()
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\poli\\segmentation')
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
mu=runif(nseg,min=5,max=50)
seg.index=rep(1:nseg,times=partition)
obs=data.frame(obs=rnorm(nobs,mean=mu[seg.index],sd=1),
time1=1:nobs)
plot(obs)
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\poli\\segmentation')
dat=read.csv('fake data.csv',as.is=T)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\poli\\segmentation')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
breakpt
mean(dat$time1)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\poli\\segmentation')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#starting values
breakpt=mean(dat$time1)
breakpt.old=breakpt
p=length(breakpt)
rand1=runif(1)
p
p0=1
breakpt.new=sort(c(breakpt.old,runif(1,0,max.time)))
p0=1/3 #death prob 2 -> 1 is (1/3) and birth prob 1
max.time=max(dat$time1)
breakpt.new=sort(c(breakpt.old,runif(1,0,max.time)))
p0=1/3 #death prob 2 -> 1 is (1/3) and birth prob 1 -> 2 is 1.
breakpt.new
runif(1,0,max.time)
runif(1,0,max.time)
runif(1,0,max.time)
runif(1,min=0,max=max.time)
max.time
breakpt.new
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat)
stats.new=get.summary.stats(breakpt=breakpt.new,dat=dat)
setwd('U:\\poli\\segmentation')
source('gibbs functions.R')
rm(list=ls(all=TRUE))
set.seed(1)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
mu=runif(nseg,min=5,max=50)
seg.index=rep(1:nseg,times=partition)
obs=data.frame(obs=rnorm(nobs,mean=mu[seg.index],sd=1),
time1=1:nobs)
plot(obs)
setwd('U:\\GIT_models\\git_segmentation_model')
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#useful stuff
max.time=max(dat$time1)
#starting values
breakpt=mean(dat$time1)
ngibbs=1000
breakpt.old=breakpt
p=length(breakpt)
rand1=runif(1)
p0=1
new.brk=runif(1,min=0,max=max.time)
if (p == 1) {
#birth
if (rand1 < 1/2){
breakpt.new=sort(c(breakpt.old,new.brk))
p0=2/3 #death prob 2 -> 1 is (1/3) and birth prob 1 -> 2 is 1/2.
}
#swap
if (rand1 > 1/2) breakpt.new=new.brk
}
if (p > 1) {
#birth
if (rand1 < 1/3) {
breakpt.new=sort(c(breakpt.old,new.brk))
}
#death
if (rand1 > 1/3 & rand1 < 2/3) {
ind=sample(1:length(breakpt.old),size=1)
breakpt.new=breakpt.old[-ind]
if (p==2) p0=3/2 #birth prob from 1 -> 2 is 1/2 and death prob from 2 -> 1 is 1/3
}
#swap
if (rand1 > 2/3) {
ind=sample(1:length(breakpt.old),size=1)
breakpt.new=sort(c(breakpt.old[-ind],new.brk))
}
}
breakpt.old
breakpt.new
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat)
stats.new=get.summary.stats(breakpt=breakpt.new,dat=dat)
stats.old
stats.new
pold=log.marg.likel(tau2=tau2,mu0=mu0,summary.stats=stats.old)
pold
summary.stats=stats.old
inv.sig2=summary.stats[,'n']+(1/tau2)
sig2=1/inv.sig2
#get mu1
num1=summary.stats[,'sum.x']+(1/tau2)*mu0
den1=summary.stats[,'n']+(1/tau2)
mu1=num1/den1
#get pieces of equation
p1=summary.stats[,'n']*log(2*pi)
p2=log(sig2/tau2)
p3=(mu1^2)/sig2
p4=summary.stats[,'sum.x2']+((mu0^2)/tau2)
p1
p2
p3
p4
log.marg.likel=function(tau2,mu0,summary.stats){
#get sig2
inv.sig2=summary.stats[,'n']+(1/tau2)
sig2=1/inv.sig2
#get mu1
num1=summary.stats[,'sum.x']+(1/tau2)*mu0
den1=summary.stats[,'n']+(1/tau2)
mu1=num1/den1
#get pieces of equation
p1=summary.stats[,'n']*log(2*pi)
p2=log(sig2/tau2)
p3=(mu1^2)/sig2
p4=summary.stats[,'sum.x2']+((mu0^2)/tau2)
sum((1/2)*(-p1+p2+p3-p4))
}
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat)
stats.new=get.summary.stats(breakpt=breakpt.new,dat=dat)
pold=log.marg.likel(tau2=tau2,mu0=mu0,summary.stats=stats.old)
pnew=log.marg.likel(tau2=tau2,mu0=mu0,summary.stats=stats.new)+log(p0)
pold
pnew
prob=exp(pnew-pold)
prob
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#useful stuff
max.time=max(dat$time1)
#starting values
breakpt=mean(dat$time1)
ngibbs=1000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,tau2=tau2,mu0=mu0)
}
breakpt
abline(v=breakpt)
length(breakpt)
rm(list=ls(all=TRUE))
set.seed(1)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
mu=runif(nseg,min=5,max=50)
seg.index=rep(1:nseg,times=partition)
obs=data.frame(obs=rnorm(nobs,mean=mu[seg.index],sd=1),
time1=1:nobs)
plot(obs~time1,data=obs)
setwd('U:\\GIT_models\\git_segmentation_model')
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#useful stuff
max.time=max(dat$time1)
#starting values
breakpt=mean(dat$time1)
ngibbs=1000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,tau2=tau2,mu0=mu0)
}
abline(h=breakpt,col='grey')
abline(v=breakpt,col='grey')
rm(list=ls(all=TRUE))
set.seed(1)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
mu=runif(nseg,min=5,max=50)
seg.index=rep(1:nseg,times=partition)
obs=data.frame(obs=rnorm(nobs,mean=mu[seg.index],sd=1),
time1=1:nobs)
plot(obs~time1,data=obs)
setwd('U:\\GIT_models\\git_segmentation_model')
write.csv(obs,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
tau2=100
mu0=0
#useful stuff
max.time=max(dat$time1)
#starting values
breakpt=mean(dat$time1)
ngibbs=10000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,tau2=tau2,mu0=mu0)
}
length(breakpt)
abline(v=breakpt,col='grey')
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
alpha=0.01
#useful stuff
max.time=max(dat$time1)
nloc=max(dat$loc.id)
#starting values
breakpt=mean(dat$time1)
ngibbs=10000
breakpt.old=breakpt
p=length(breakpt)
rand1=runif(1)
p0=1
new.brk=runif(1,min=0,max=max.time)
if (p == 1) {
#birth
if (rand1 < 1/2){
breakpt.new=sort(c(breakpt.old,new.brk))
p0=2/3 #death prob 2 -> 1 is (1/3) and birth prob 1 -> 2 is 1/2.
}
#swap
if (rand1 > 1/2) breakpt.new=new.brk
}
if (p > 1) {
#birth
if (rand1 < 1/3) {
breakpt.new=sort(c(breakpt.old,new.brk))
}
#death
if (rand1 > 1/3 & rand1 < 2/3) {
ind=sample(1:length(breakpt.old),size=1)
breakpt.new=breakpt.old[-ind]
if (p==2) p0=3/2 #birth prob from 1 -> 2 is 1/2 and death prob from 2 -> 1 is 1/3
}
#swap
if (rand1 > 2/3) {
ind=sample(1:length(breakpt.old),size=1)
breakpt.new=sort(c(breakpt.old[-ind],new.brk))
}
}
library(microbenchmark)
microbenchmark(
#get sufficient statistics
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat,nloc=nloc),
#get marginal loglikel
pold=log.marg.likel(alpha=alpha,summary.stats=stats.old,nloc=nloc)
)
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat,nloc=nloc)
library(microbenchmark)
microbenchmark(
#get sufficient statistics
stats.old=get.summary.stats(breakpt=breakpt.old,dat=dat,nloc=nloc),
#get marginal loglikel
pold=log.marg.likel(alpha=alpha,summary.stats=stats.old,nloc=nloc)
)
dim(dat)
head(da)
head(dat)
nloc
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(1)
nobs=9000
nseg=30
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
seg.index=rep(1:nseg,times=partition)
nloc=300
prob=rdirichlet(nseg,rep(0.01,nloc))
obs=rep(NA,nobs)
for (i in 1:nobs){
tmp=rmultinom(1,size=1,prob=prob[seg.index[i],])
obs[i]=which(tmp==1)
}
plot(obs)
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(1)
nobs=9000
nseg=30
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
seg.index=rep(1:nseg,times=partition)
nloc=300
prob=rdirichlet(nseg,rep(0.01,nloc))
obs=rep(NA,nobs)
for (i in 1:nobs){
tmp=rmultinom(1,size=1,prob=prob[seg.index[i],])
obs[i]=which(tmp==1)
}
plot(obs)
abline(v=cumsum(partition))
obs1=data.frame(loc.id=obs)
obs1$time1=1:nobs
setwd('U:\\GIT_models\\git_segmentation_model')
write.csv(obs1,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
alpha=0.01
#useful stuff
max.time=max(dat$time1)
nloc=max(dat$loc.id)
#starting values
breakpt=mean(dat$time1)
ngibbs=10000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,
alpha=alpha,nloc=nloc)
}
length(breakpt)
abline(v=breakpt,lty=3,col='green')
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
alpha=0.01
#useful stuff
max.time=max(dat$time1)
nloc=max(dat$loc.id)
#starting values
breakpt=mean(dat$time1)
ngibbs=10000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,
alpha=alpha,nloc=nloc)
}
length(breakpt)
abline(v=breakpt,lty=3,col='green')
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(1)
nobs=9000
nseg=30
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
seg.index=rep(1:nseg,times=partition)
nloc=300
prob=rdirichlet(nseg,rep(0.01,nloc))
obs=rep(NA,nobs)
for (i in 1:nobs){
tmp=rmultinom(1,size=1,prob=prob[seg.index[i],])
obs[i]=which(tmp==1)
}
plot(obs)
abline(v=cumsum(partition))
obs1=data.frame(loc.id=obs)
obs1$time1=1:nobs
setwd('U:\\GIT_models\\git_segmentation_model')
write.csv(obs1,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_model')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
alpha=0.01
#useful stuff
max.time=max(dat$time1)
nloc=max(dat$loc.id)
#starting values
breakpt=mean(dat$time1)
ngibbs=10000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,
alpha=alpha,nloc=nloc)
}
length(breakpt)
abline(v=breakpt,lty=3,col='green')
